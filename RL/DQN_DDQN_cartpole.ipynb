{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18871be9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21d66482",
    "outputId": "de6600e7-37a3-47ed-e1b2-5dd638c0e5ac"
   },
   "source": [
    "# DQN and DDQN\n",
    "### Implements DQN and DDQN on CartPole environment (or any other environment that doesnâ€™t require frame stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9180e1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (1.23.3)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (6.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f03f06",
   "metadata": {
    "id": "08f03f06"
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff82b1f",
   "metadata": {
    "id": "aff82b1f"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network, subclass of torch.nn.Module\n",
    "    \"\"\"\n",
    "    def __init__(self, n_actions, state_size):\n",
    "        \"\"\"\n",
    "        Initializes neural network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(state_size, state_size * 2),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(state_size * 2, n_actions),\n",
    "                                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs forward pass in network\n",
    "\n",
    "        :param x: network input\n",
    "        :return:  network prediction\n",
    "        \"\"\"\n",
    "        y = self.linear_relu_stack(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670d35d",
   "metadata": {
    "id": "c670d35d"
   },
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17177962",
   "metadata": {
    "id": "17177962"
   },
   "outputs": [],
   "source": [
    "class ExperiencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset used to train the online network, subclass of torch.utils.data.dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, agent, memory_subset):\n",
    "        \"\"\"\n",
    "        Initializes dataset\n",
    "\n",
    "        :param agent:         agent thats beeing trained\n",
    "        :param memory_subset: experiences sampled randomly from agent.replay_memory\n",
    "        :return:              None\n",
    "        \"\"\"\n",
    "        #labels and inputs lists\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "\n",
    "        #loop experiences\n",
    "        for experience in memory_subset:\n",
    "\n",
    "            #get network input and corresponding label\n",
    "            input_, label = agent.algorithm(experience)\n",
    "\n",
    "            #append input and label to corresponding lists\n",
    "            self.labels.append(label)\n",
    "            self.inputs.append(input_)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Gets length of dataset\n",
    "\n",
    "        :return: length of dataset\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetches network input and correspodning label\n",
    "\n",
    "        :param idx: list index for network input and corresponding label\n",
    "        :return:    network input and corresponding label\n",
    "        \"\"\"\n",
    "        input_, label = self.inputs[idx], self.labels[idx]\n",
    "        return input_, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eaf21b",
   "metadata": {
    "id": "82eaf21b"
   },
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3d834a",
   "metadata": {
    "id": "4e3d834a"
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"\n",
    "    Deep Q-learning agent\n",
    "    \"\"\"\n",
    "    def __init__(self, n_actions, state_size, algorithm, copy_frequency=100, batch_size=320, device='cpu', epsilon_end=0.05, epsilon_start=1,\n",
    "                 gamma=0.99, loss_fn='MSELoss', learning_rate=0.00025, memory_capacity=10000, mini_batch_size=32,\n",
    "                 optimizer='RMSprop'):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes agent\n",
    "\n",
    "        :param algorithm:        algorithm used for creating labels in training. Options: 'DQN', 'DDQN'\n",
    "        :param batch_size:       size of batches used in training\n",
    "        :param copy_frequency:   frequency of copying online network to offline network\n",
    "        :param device:           device on which training is performed\n",
    "        :param epsilon_end:      final probability of choosing random action\n",
    "        :param epsilon_start:    initial probability of choosing random action\n",
    "        :param gamma:            discount factor used for target q-value\n",
    "        :param loss_fn:          loss function used for training self.NN_target. Options: all loss functions in torch.nn\n",
    "        :param memory_capacity:  capacity of memory\n",
    "        :param mini_batch_size:  size of mini batches in training\n",
    "        :param n_actions:        number of actions available in environment\n",
    "        :param optimizer:        optimizer used for training self.NN_pred. Options: all optimizers in torch.optim\n",
    "        :param state_size:       size of state (flattened)\n",
    "        :return:                 None\n",
    "        \"\"\"\n",
    "        self.actions = range(n_actions)\n",
    "        self.algorithm = getattr(self, algorithm)\n",
    "        self.batch_size = batch_size\n",
    "        self.copy_frequency = copy_frequency\n",
    "        self.device = device\n",
    "        self.NN_pred = NeuralNetwork(n_actions, state_size).to(device)\n",
    "        self.NN_target = copy.deepcopy(self.NN_pred)\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.epsilon = epsilon_start\n",
    "        self.gamma = gamma\n",
    "        self.loss_fn = getattr(nn, loss_fn)()\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.memory_capacity = memory_capacity\n",
    "        self.optimizer = getattr(torch.optim, optimizer)(self.NN_pred.parameters(), lr = learning_rate)\n",
    "        self.replay_memory = []\n",
    "\n",
    "\n",
    "    def save_experience(self, state, action, reward, next_state, terminated, truncated):\n",
    "        \"\"\"\n",
    "        Saves experience in agents memory\n",
    "\n",
    "        :param state:      agents state in environment\n",
    "        :param action:     action performed by agent\n",
    "        :param reward:     reward recieved by performing action in state\n",
    "        :param next_state: next state reached by performing action in state\n",
    "        :param terminated: true if next_state is a terminating state, otherwise false\n",
    "        :param truncated:  true if episode has been truncated, otherwise false\n",
    "        :return:           None\n",
    "        \"\"\"\n",
    "        #removes oldest experience from memory\n",
    "        if len(self.replay_memory) == self.memory_capacity:\n",
    "            self.replay_memory.pop(0)\n",
    "\n",
    "        #adds new experience to memory\n",
    "        self.replay_memory.append([state, action, reward, next_state, terminated, truncated])\n",
    "\n",
    "    def select_action(self, state):\n",
    "        \"\"\"\n",
    "        Selects action from actions\n",
    "\n",
    "        :param state: current state\n",
    "        :return:      selected action\n",
    "        \"\"\"\n",
    "        #selects random action with probability = epsilon\n",
    "        if random.random() < self.epsilon:\n",
    "            action = random.choice(self.actions)\n",
    "\n",
    "        #selects maximizing action with probability 1-epsilon\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                action = torch.argmax(self.NN_pred(state)).item()\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains self.NN_pred\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        #select random memory subset and create dataset and dataloader\n",
    "        memory_subset = random.choices(self.replay_memory, k = self.batch_size)\n",
    "        training_data = ExperiencesDataset(self, memory_subset)\n",
    "        train_dataloader = DataLoader(training_data, batch_size= self.mini_batch_size, shuffle=False)\n",
    "\n",
    "        #loop batches in dataloader\n",
    "        for X, Y in train_dataloader:\n",
    "\n",
    "            #make predictions\n",
    "            pred = self.NN_pred(X)\n",
    "\n",
    "            #calculate loss\n",
    "            loss = self.loss_fn(pred, Y)\n",
    "\n",
    "            #backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            #update parameters\n",
    "            self.optimizer.step()\n",
    "\n",
    "            #reset gradients to zero\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Copies prediction network to target network\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.NN_target = copy.deepcopy(self.NN_pred)\n",
    "\n",
    "    def calc_epsilon(self, episode, n_episodes):\n",
    "        \"\"\"\n",
    "        Decays epsilon\n",
    "\n",
    "        :param episode:    current episode number\n",
    "        :param n_episodes: total number of episodes\n",
    "        :return:           None\n",
    "        \"\"\"\n",
    "        #calculates new epsilon by performing linear interpolation\n",
    "        self.epsilon = self.epsilon_start - (((self.epsilon_start - self.epsilon_end) / n_episodes) * episode)\n",
    "\n",
    "    def DQN(self, experience):\n",
    "        \"\"\"\n",
    "        Fetches network input and calculates corresponding label\n",
    "        in accordance with DQN-algorithm\n",
    "\n",
    "        :param experience: one agent experience, type: [state, action, reward, next_state, terminated, truncated]\n",
    "        :return:           network input and corresponding label\n",
    "        \"\"\"\n",
    "        #unwrap experience\n",
    "        state, action, reward, next_state, terminated, truncated = experience\n",
    "\n",
    "        #calculate Q-value label\n",
    "        with torch.no_grad():\n",
    "            label = self.NN_pred(state)\n",
    "            if truncated:\n",
    "                label[action] = reward\n",
    "            elif terminated:\n",
    "                label[action] = 0\n",
    "            else:\n",
    "                label[action] = reward + self.gamma * torch.max(self.NN_target(next_state))\n",
    "\n",
    "        return state, label\n",
    "\n",
    "    def DDQN(self, experience):\n",
    "        \"\"\"\n",
    "        Fetches network input and calculates corresponding label\n",
    "        in accordance with Double DQN-algorithm\n",
    "\n",
    "        :param experience: one agent experience, type: [state, action, reward, next_state, terminated, truncated]\n",
    "        :return:           network input and corresponding label\n",
    "        \"\"\"\n",
    "        #unwrap experience\n",
    "        state, performed_action, reward, next_state, terminated, truncated = experience\n",
    "\n",
    "        #calculate Q-value label\n",
    "        with torch.no_grad():\n",
    "            label = self.NN_pred(state)\n",
    "            if truncated:\n",
    "                label[performed_action] = reward\n",
    "            elif terminated:\n",
    "                label[performed_action] = 0\n",
    "            else:\n",
    "                maximizing_action = torch.argmax(label)\n",
    "                maximizing_action_value = self.NN_target(next_state)[maximizing_action]\n",
    "                label[performed_action] = reward + self.gamma * maximizing_action_value\n",
    "\n",
    "        return state, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6de96",
   "metadata": {
    "id": "0ca6de96"
   },
   "source": [
    "# Main\n",
    "### Change algorithm by changing the 'algorithm' variable. \n",
    "### Cell can be stopped during run time and still show results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8adbea9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8adbea9b",
    "outputId": "9d0279f2-c49d-43b7-b960-0e56086cd873",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Episode reward: 36.0, Elapsed time: 1.6701221466064452e-05 minutes, Epsilon 1\n",
      "Episode: 2, Episode reward: 16.0, Elapsed time: 3.158251444498698e-05 minutes, Epsilon 0.9981\n",
      "Episode: 3, Episode reward: 10.0, Elapsed time: 3.158251444498698e-05 minutes, Epsilon 0.9962\n",
      "Episode: 4, Episode reward: 21.0, Elapsed time: 4.841089248657227e-05 minutes, Epsilon 0.9943\n",
      "Episode: 5, Episode reward: 31.0, Elapsed time: 6.510019302368164e-05 minutes, Epsilon 0.9924\n",
      "Episode: 6, Episode reward: 19.0, Elapsed time: 8.173386255900065e-05 minutes, Epsilon 0.9905\n",
      "Episode: 7, Episode reward: 33.0, Elapsed time: 9.845097859700521e-05 minutes, Epsilon 0.9886\n",
      "Episode: 8, Episode reward: 17.0, Elapsed time: 0.00011525551478068034 minutes, Epsilon 0.9867\n",
      "Episode: 9, Episode reward: 16.0, Elapsed time: 0.00013175010681152344 minutes, Epsilon 0.9848\n",
      "Episode: 10, Episode reward: 32.0, Elapsed time: 0.000271145502726237 minutes, Epsilon 0.9829\n",
      "Episode: 11, Episode reward: 45.0, Elapsed time: 0.0003039280573527018 minutes, Epsilon 0.981\n",
      "Episode: 12, Episode reward: 16.0, Elapsed time: 0.00032071272532145184 minutes, Epsilon 0.9791\n",
      "Episode: 13, Episode reward: 11.0, Elapsed time: 0.0003541707992553711 minutes, Epsilon 0.9772\n",
      "Episode: 14, Episode reward: 18.0, Elapsed time: 0.0014751394589742025 minutes, Epsilon 0.9753000000000001\n",
      "Episode: 15, Episode reward: 9.0, Elapsed time: 0.011429003874460856 minutes, Epsilon 0.9734\n",
      "Episode: 16, Episode reward: 17.0, Elapsed time: 0.03127769629160563 minutes, Epsilon 0.9715\n",
      "Episode: 17, Episode reward: 12.0, Elapsed time: 0.04460411866505941 minutes, Epsilon 0.9696\n",
      "Episode: 18, Episode reward: 15.0, Elapsed time: 0.060834829012552896 minutes, Epsilon 0.9677\n",
      "Episode: 19, Episode reward: 44.0, Elapsed time: 0.10882592598597209 minutes, Epsilon 0.9658\n",
      "Episode: 20, Episode reward: 13.0, Elapsed time: 0.12151662111282349 minutes, Epsilon 0.9639\n",
      "Episode: 21, Episode reward: 12.0, Elapsed time: 0.13305832942326865 minutes, Epsilon 0.962\n",
      "Episode: 22, Episode reward: 9.0, Elapsed time: 0.14190210501352946 minutes, Epsilon 0.9601\n",
      "Episode: 23, Episode reward: 38.0, Elapsed time: 0.18026605049769084 minutes, Epsilon 0.9582\n",
      "Episode: 24, Episode reward: 81.0, Elapsed time: 0.26793478727340697 minutes, Epsilon 0.9563\n",
      "Episode: 25, Episode reward: 62.0, Elapsed time: 0.33282553354899086 minutes, Epsilon 0.9544\n",
      "Episode: 26, Episode reward: 32.0, Elapsed time: 0.36515466769536337 minutes, Epsilon 0.9525\n",
      "Episode: 27, Episode reward: 9.0, Elapsed time: 0.3740132848421733 minutes, Epsilon 0.9506\n",
      "Episode: 28, Episode reward: 16.0, Elapsed time: 0.3913328687349955 minutes, Epsilon 0.9487\n",
      "Episode: 29, Episode reward: 10.0, Elapsed time: 0.40320204893747963 minutes, Epsilon 0.9468\n",
      "Episode: 30, Episode reward: 13.0, Elapsed time: 0.41614749034245807 minutes, Epsilon 0.9449\n",
      "Episode: 31, Episode reward: 38.0, Elapsed time: 0.45570285320281984 minutes, Epsilon 0.943\n",
      "Episode: 32, Episode reward: 10.0, Elapsed time: 0.4669817328453064 minutes, Epsilon 0.9411\n",
      "Episode: 33, Episode reward: 23.0, Elapsed time: 0.4894087394078573 minutes, Epsilon 0.9392\n",
      "Episode: 34, Episode reward: 13.0, Elapsed time: 0.5022362112998963 minutes, Epsilon 0.9373\n",
      "Episode: 35, Episode reward: 23.0, Elapsed time: 0.5246814290682474 minutes, Epsilon 0.9354\n",
      "Episode: 36, Episode reward: 37.0, Elapsed time: 0.5604881604512533 minutes, Epsilon 0.9335\n",
      "Episode: 37, Episode reward: 8.0, Elapsed time: 0.5685706377029419 minutes, Epsilon 0.9316\n",
      "Episode: 38, Episode reward: 16.0, Elapsed time: 0.5842566887537638 minutes, Epsilon 0.9297\n",
      "Episode: 39, Episode reward: 13.0, Elapsed time: 0.5970908323923747 minutes, Epsilon 0.9278\n",
      "Episode: 40, Episode reward: 29.0, Elapsed time: 0.6255680561065674 minutes, Epsilon 0.9259\n",
      "Episode: 41, Episode reward: 23.0, Elapsed time: 0.6536330699920654 minutes, Epsilon 0.924\n",
      "Episode: 42, Episode reward: 16.0, Elapsed time: 0.6726682623227437 minutes, Epsilon 0.9221\n",
      "Episode: 43, Episode reward: 37.0, Elapsed time: 0.7149391571680704 minutes, Epsilon 0.9202\n",
      "Episode: 44, Episode reward: 18.0, Elapsed time: 0.7325079878171284 minutes, Epsilon 0.9183\n",
      "Episode: 45, Episode reward: 31.0, Elapsed time: 0.7660603125890096 minutes, Epsilon 0.9164\n",
      "Episode: 46, Episode reward: 24.0, Elapsed time: 0.7922176798184712 minutes, Epsilon 0.9145\n",
      "Episode: 47, Episode reward: 15.0, Elapsed time: 0.8114788452784221 minutes, Epsilon 0.9126\n",
      "Episode: 48, Episode reward: 8.0, Elapsed time: 0.8196260094642639 minutes, Epsilon 0.9107\n",
      "Episode: 49, Episode reward: 13.0, Elapsed time: 0.8326647639274597 minutes, Epsilon 0.9088\n",
      "Episode: 50, Episode reward: 21.0, Elapsed time: 0.8538999080657959 minutes, Epsilon 0.9069\n",
      "Episode: 51, Episode reward: 15.0, Elapsed time: 0.8689888000488282 minutes, Epsilon 0.905\n",
      "Episode: 52, Episode reward: 17.0, Elapsed time: 0.8890818556149801 minutes, Epsilon 0.9031\n",
      "Episode: 53, Episode reward: 14.0, Elapsed time: 0.9028624693552653 minutes, Epsilon 0.9012\n",
      "Episode: 54, Episode reward: 19.0, Elapsed time: 0.9215904951095581 minutes, Epsilon 0.8993\n",
      "Episode: 55, Episode reward: 56.0, Elapsed time: 0.9763272802035013 minutes, Epsilon 0.8974\n",
      "Episode: 56, Episode reward: 12.0, Elapsed time: 0.9955838362375895 minutes, Epsilon 0.8955\n",
      "Episode: 57, Episode reward: 30.0, Elapsed time: 1.043962307771047 minutes, Epsilon 0.8936\n",
      "Episode: 58, Episode reward: 43.0, Elapsed time: 1.1090939839680989 minutes, Epsilon 0.8917\n",
      "Episode: 59, Episode reward: 24.0, Elapsed time: 1.1475667913754781 minutes, Epsilon 0.8898\n",
      "Episode: 60, Episode reward: 17.0, Elapsed time: 1.1714918772379557 minutes, Epsilon 0.8879\n",
      "Episode: 61, Episode reward: 12.0, Elapsed time: 1.1900552988052369 minutes, Epsilon 0.886\n",
      "Episode: 62, Episode reward: 15.0, Elapsed time: 1.21215478181839 minutes, Epsilon 0.8841\n",
      "Episode: 63, Episode reward: 16.0, Elapsed time: 1.234651497999827 minutes, Epsilon 0.8822\n",
      "Episode: 64, Episode reward: 24.0, Elapsed time: 1.268210514386495 minutes, Epsilon 0.8803\n",
      "Episode: 65, Episode reward: 15.0, Elapsed time: 1.2879115025202432 minutes, Epsilon 0.8784\n",
      "Episode: 66, Episode reward: 33.0, Elapsed time: 1.3339069565137227 minutes, Epsilon 0.8765000000000001\n",
      "Episode: 67, Episode reward: 53.0, Elapsed time: 1.4077143351236978 minutes, Epsilon 0.8746\n",
      "Episode: 68, Episode reward: 15.0, Elapsed time: 1.4286758502324421 minutes, Epsilon 0.8727\n",
      "Episode: 69, Episode reward: 15.0, Elapsed time: 1.4495481808980306 minutes, Epsilon 0.8708\n",
      "Episode: 70, Episode reward: 17.0, Elapsed time: 1.4730985601743063 minutes, Epsilon 0.8689\n",
      "Episode: 71, Episode reward: 44.0, Elapsed time: 1.5335667689641317 minutes, Epsilon 0.867\n",
      "Episode: 72, Episode reward: 13.0, Elapsed time: 1.551401666800181 minutes, Epsilon 0.8651\n",
      "Episode: 73, Episode reward: 31.0, Elapsed time: 1.5944874167442322 minutes, Epsilon 0.8632\n",
      "Episode: 74, Episode reward: 29.0, Elapsed time: 1.6349792758623758 minutes, Epsilon 0.8613\n",
      "Episode: 75, Episode reward: 15.0, Elapsed time: 1.6557758768399558 minutes, Epsilon 0.8593999999999999\n",
      "Episode: 76, Episode reward: 37.0, Elapsed time: 1.7070056637128195 minutes, Epsilon 0.8575\n",
      "Episode: 77, Episode reward: 32.0, Elapsed time: 1.7504676421483358 minutes, Epsilon 0.8556\n",
      "Episode: 78, Episode reward: 18.0, Elapsed time: 1.7754743138949076 minutes, Epsilon 0.8537\n",
      "Episode: 79, Episode reward: 23.0, Elapsed time: 1.8052829265594483 minutes, Epsilon 0.8518\n",
      "Episode: 80, Episode reward: 44.0, Elapsed time: 1.8674128929773965 minutes, Epsilon 0.8499\n",
      "Episode: 81, Episode reward: 12.0, Elapsed time: 1.8842199365297954 minutes, Epsilon 0.848\n",
      "Episode: 82, Episode reward: 64.0, Elapsed time: 1.9727962772051493 minutes, Epsilon 0.8461\n",
      "Episode: 83, Episode reward: 52.0, Elapsed time: 2.04517271121343 minutes, Epsilon 0.8442000000000001\n",
      "Episode: 84, Episode reward: 14.0, Elapsed time: 2.064691654841105 minutes, Epsilon 0.8423\n",
      "Episode: 85, Episode reward: 51.0, Elapsed time: 2.1353747129440306 minutes, Epsilon 0.8404\n",
      "Episode: 86, Episode reward: 50.0, Elapsed time: 2.2048004309336346 minutes, Epsilon 0.8385\n",
      "Episode: 87, Episode reward: 23.0, Elapsed time: 2.236823507150014 minutes, Epsilon 0.8366\n",
      "Episode: 88, Episode reward: 17.0, Elapsed time: 2.261148432890574 minutes, Epsilon 0.8347\n",
      "Episode: 89, Episode reward: 21.0, Elapsed time: 2.293674190839132 minutes, Epsilon 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 90, Episode reward: 58.0, Elapsed time: 2.3742159088452657 minutes, Epsilon 0.8309\n",
      "Episode: 91, Episode reward: 14.0, Elapsed time: 2.3931324044863382 minutes, Epsilon 0.829\n",
      "Episode: 92, Episode reward: 76.0, Elapsed time: 2.483186900615692 minutes, Epsilon 0.8271\n",
      "Episode: 93, Episode reward: 15.0, Elapsed time: 2.501007076104482 minutes, Epsilon 0.8251999999999999\n",
      "Episode: 94, Episode reward: 17.0, Elapsed time: 2.521032663186391 minutes, Epsilon 0.8233\n",
      "Episode: 95, Episode reward: 25.0, Elapsed time: 2.5502684513727822 minutes, Epsilon 0.8214\n",
      "Episode: 96, Episode reward: 22.0, Elapsed time: 2.5758246382077536 minutes, Epsilon 0.8195\n",
      "Episode: 97, Episode reward: 47.0, Elapsed time: 2.6311230778694155 minutes, Epsilon 0.8176\n",
      "Episode: 98, Episode reward: 19.0, Elapsed time: 2.6534852743148805 minutes, Epsilon 0.8157\n",
      "Episode: 99, Episode reward: 13.0, Elapsed time: 2.6688018600145975 minutes, Epsilon 0.8138\n",
      "Episode: 100, Episode reward: 59.0, Elapsed time: 2.7375564495722453 minutes, Epsilon 0.8119000000000001\n",
      "Episode: 101, Episode reward: 19.0, Elapsed time: 2.7600340485572814 minutes, Epsilon 0.81\n",
      "Episode: 102, Episode reward: 42.0, Elapsed time: 2.81006338596344 minutes, Epsilon 0.8081\n",
      "Episode: 103, Episode reward: 22.0, Elapsed time: 2.836787990729014 minutes, Epsilon 0.8062\n",
      "Episode: 104, Episode reward: 23.0, Elapsed time: 2.8638178586959837 minutes, Epsilon 0.8043\n",
      "Episode: 105, Episode reward: 12.0, Elapsed time: 2.877049227555593 minutes, Epsilon 0.8024\n",
      "Episode: 106, Episode reward: 35.0, Elapsed time: 2.9218021790186564 minutes, Epsilon 0.8005\n",
      "Episode: 107, Episode reward: 39.0, Elapsed time: 2.966815535227458 minutes, Epsilon 0.7986\n",
      "Episode: 108, Episode reward: 84.0, Elapsed time: 3.062707304954529 minutes, Epsilon 0.7967\n",
      "Episode: 109, Episode reward: 66.0, Elapsed time: 3.138727939128876 minutes, Epsilon 0.7948\n",
      "Episode: 110, Episode reward: 81.0, Elapsed time: 3.2320600350697837 minutes, Epsilon 0.7928999999999999\n",
      "Episode: 111, Episode reward: 12.0, Elapsed time: 3.2463584621747335 minutes, Epsilon 0.791\n",
      "Episode: 112, Episode reward: 57.0, Elapsed time: 3.3132399241129558 minutes, Epsilon 0.7891\n",
      "Episode: 113, Episode reward: 33.0, Elapsed time: 3.3512014945348105 minutes, Epsilon 0.7872\n",
      "Episode: 114, Episode reward: 39.0, Elapsed time: 3.3961938699086507 minutes, Epsilon 0.7853\n",
      "Episode: 115, Episode reward: 38.0, Elapsed time: 3.4434343218803405 minutes, Epsilon 0.7834\n",
      "Episode: 116, Episode reward: 14.0, Elapsed time: 3.4603692809740703 minutes, Epsilon 0.7815\n",
      "Episode: 117, Episode reward: 12.0, Elapsed time: 3.474098817507426 minutes, Epsilon 0.7796\n",
      "Episode: 118, Episode reward: 39.0, Elapsed time: 3.520474906762441 minutes, Epsilon 0.7777000000000001\n",
      "Episode: 119, Episode reward: 62.0, Elapsed time: 3.591428530216217 minutes, Epsilon 0.7758\n",
      "Episode: 120, Episode reward: 10.0, Elapsed time: 3.6031280676523845 minutes, Epsilon 0.7739\n",
      "Episode: 121, Episode reward: 53.0, Elapsed time: 3.6641454378763836 minutes, Epsilon 0.772\n",
      "Episode: 122, Episode reward: 15.0, Elapsed time: 3.6817853689193725 minutes, Epsilon 0.7701\n",
      "Episode: 123, Episode reward: 42.0, Elapsed time: 3.7298383394877117 minutes, Epsilon 0.7682\n",
      "Episode: 124, Episode reward: 18.0, Elapsed time: 3.751155960559845 minutes, Epsilon 0.7663\n",
      "Episode: 125, Episode reward: 44.0, Elapsed time: 3.803925263881683 minutes, Epsilon 0.7644\n",
      "Episode: 126, Episode reward: 16.0, Elapsed time: 3.8225412567456565 minutes, Epsilon 0.7625\n",
      "Episode: 127, Episode reward: 25.0, Elapsed time: 3.852558199564616 minutes, Epsilon 0.7605999999999999\n",
      "Episode: 128, Episode reward: 23.0, Elapsed time: 3.8801915407180787 minutes, Epsilon 0.7587\n",
      "Episode: 129, Episode reward: 26.0, Elapsed time: 3.9125229994455974 minutes, Epsilon 0.7568\n",
      "Episode: 130, Episode reward: 12.0, Elapsed time: 3.9268360217412313 minutes, Epsilon 0.7549\n",
      "Episode: 131, Episode reward: 52.0, Elapsed time: 3.986873543262482 minutes, Epsilon 0.753\n",
      "Episode: 132, Episode reward: 15.0, Elapsed time: 4.004641425609589 minutes, Epsilon 0.7511\n",
      "Episode: 133, Episode reward: 49.0, Elapsed time: 4.060906271139781 minutes, Epsilon 0.7492\n",
      "Episode: 134, Episode reward: 22.0, Elapsed time: 4.086819430192311 minutes, Epsilon 0.7473000000000001\n",
      "Episode: 135, Episode reward: 39.0, Elapsed time: 4.131443150838217 minutes, Epsilon 0.7454000000000001\n",
      "Episode: 136, Episode reward: 48.0, Elapsed time: 4.186736110846201 minutes, Epsilon 0.7435\n",
      "Episode: 137, Episode reward: 19.0, Elapsed time: 4.2088802297910055 minutes, Epsilon 0.7416\n",
      "Episode: 138, Episode reward: 53.0, Elapsed time: 4.27059131860733 minutes, Epsilon 0.7397\n",
      "Episode: 139, Episode reward: 37.0, Elapsed time: 4.3132940848668415 minutes, Epsilon 0.7378\n",
      "Episode: 140, Episode reward: 22.0, Elapsed time: 4.339344394207001 minutes, Epsilon 0.7359\n",
      "Episode: 141, Episode reward: 65.0, Elapsed time: 4.414099923769633 minutes, Epsilon 0.734\n",
      "Episode: 142, Episode reward: 20.0, Elapsed time: 4.43731103738149 minutes, Epsilon 0.7321\n",
      "Episode: 143, Episode reward: 71.0, Elapsed time: 4.519341890017191 minutes, Epsilon 0.7302\n",
      "Episode: 144, Episode reward: 22.0, Elapsed time: 4.544973234335582 minutes, Epsilon 0.7283\n",
      "Episode: 145, Episode reward: 38.0, Elapsed time: 4.588694457213084 minutes, Epsilon 0.7263999999999999\n",
      "Episode: 146, Episode reward: 15.0, Elapsed time: 4.60697805484136 minutes, Epsilon 0.7244999999999999\n",
      "Episode: 147, Episode reward: 32.0, Elapsed time: 4.643585360050201 minutes, Epsilon 0.7226\n",
      "Episode: 148, Episode reward: 16.0, Elapsed time: 4.662050052483877 minutes, Epsilon 0.7207\n",
      "Episode: 149, Episode reward: 47.0, Elapsed time: 4.7161638299624125 minutes, Epsilon 0.7188\n",
      "Episode: 150, Episode reward: 12.0, Elapsed time: 4.729448632399241 minutes, Epsilon 0.7169\n",
      "Episode: 151, Episode reward: 34.0, Elapsed time: 4.769372022151947 minutes, Epsilon 0.7150000000000001\n",
      "Episode: 152, Episode reward: 27.0, Elapsed time: 4.800349958737692 minutes, Epsilon 0.7131000000000001\n",
      "Episode: 153, Episode reward: 73.0, Elapsed time: 4.884877129395803 minutes, Epsilon 0.7112\n",
      "Episode: 154, Episode reward: 27.0, Elapsed time: 4.917366186777751 minutes, Epsilon 0.7093\n",
      "Episode: 155, Episode reward: 37.0, Elapsed time: 4.960461934407552 minutes, Epsilon 0.7074\n",
      "Episode: 156, Episode reward: 33.0, Elapsed time: 4.999871718883514 minutes, Epsilon 0.7055\n",
      "Episode: 157, Episode reward: 65.0, Elapsed time: 5.07424966096878 minutes, Epsilon 0.7036\n",
      "Episode: 158, Episode reward: 39.0, Elapsed time: 5.119172958532969 minutes, Epsilon 0.7017\n",
      "Episode: 159, Episode reward: 19.0, Elapsed time: 5.140367356936137 minutes, Epsilon 0.6998\n",
      "Episode: 160, Episode reward: 34.0, Elapsed time: 5.180753648281097 minutes, Epsilon 0.6979\n",
      "Episode: 161, Episode reward: 20.0, Elapsed time: 5.2039317409197485 minutes, Epsilon 0.696\n",
      "Episode: 162, Episode reward: 35.0, Elapsed time: 5.262895842393239 minutes, Epsilon 0.6940999999999999\n",
      "Episode: 163, Episode reward: 97.0, Elapsed time: 5.460049446423849 minutes, Epsilon 0.6921999999999999\n",
      "Episode: 164, Episode reward: 18.0, Elapsed time: 5.490109181404113 minutes, Epsilon 0.6903\n",
      "Episode: 165, Episode reward: 46.0, Elapsed time: 5.566962802410126 minutes, Epsilon 0.6884\n",
      "Episode: 166, Episode reward: 11.0, Elapsed time: 5.585122776031494 minutes, Epsilon 0.6865\n",
      "Episode: 167, Episode reward: 39.0, Elapsed time: 5.651432089010874 minutes, Epsilon 0.6846\n",
      "Episode: 168, Episode reward: 63.0, Elapsed time: 5.755179723103841 minutes, Epsilon 0.6827\n",
      "Episode: 169, Episode reward: 57.0, Elapsed time: 5.847021778424581 minutes, Epsilon 0.6808000000000001\n",
      "Episode: 170, Episode reward: 35.0, Elapsed time: 5.907261637846629 minutes, Epsilon 0.6789000000000001\n",
      "Episode: 171, Episode reward: 63.0, Elapsed time: 6.0196095625559485 minutes, Epsilon 0.677\n",
      "Episode: 172, Episode reward: 86.0, Elapsed time: 6.162357274691264 minutes, Epsilon 0.6751\n",
      "Episode: 173, Episode reward: 40.0, Elapsed time: 6.227652700742086 minutes, Epsilon 0.6732\n",
      "Episode: 174, Episode reward: 47.0, Elapsed time: 6.306355897585551 minutes, Epsilon 0.6713\n",
      "Episode: 175, Episode reward: 13.0, Elapsed time: 6.328102751572927 minutes, Epsilon 0.6694\n",
      "Episode: 176, Episode reward: 15.0, Elapsed time: 6.359904901186625 minutes, Epsilon 0.6675\n",
      "Episode: 177, Episode reward: 28.0, Elapsed time: 6.410307276248932 minutes, Epsilon 0.6656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 178, Episode reward: 47.0, Elapsed time: 6.504415627320608 minutes, Epsilon 0.6637\n",
      "Episode: 179, Episode reward: 53.0, Elapsed time: 6.6028060952822365 minutes, Epsilon 0.6617999999999999\n",
      "Episode: 180, Episode reward: 21.0, Elapsed time: 6.641251305739085 minutes, Epsilon 0.6598999999999999\n",
      "Episode: 181, Episode reward: 60.0, Elapsed time: 6.744365588823954 minutes, Epsilon 0.6579999999999999\n",
      "Episode: 182, Episode reward: 144.0, Elapsed time: 7.003186766306559 minutes, Epsilon 0.6561\n",
      "Episode: 183, Episode reward: 53.0, Elapsed time: 7.098926381270091 minutes, Epsilon 0.6542\n",
      "Episode: 184, Episode reward: 45.0, Elapsed time: 7.175337541103363 minutes, Epsilon 0.6523\n",
      "Episode: 185, Episode reward: 20.0, Elapsed time: 7.213793512185415 minutes, Epsilon 0.6504\n",
      "Episode: 186, Episode reward: 10.0, Elapsed time: 7.23180121978124 minutes, Epsilon 0.6485000000000001\n",
      "Episode: 187, Episode reward: 58.0, Elapsed time: 7.3450200200080875 minutes, Epsilon 0.6466000000000001\n",
      "Episode: 188, Episode reward: 77.0, Elapsed time: 7.4691040714581804 minutes, Epsilon 0.6447\n",
      "Episode: 189, Episode reward: 95.0, Elapsed time: 7.635041515032451 minutes, Epsilon 0.6428\n",
      "Episode: 190, Episode reward: 31.0, Elapsed time: 7.691382241249085 minutes, Epsilon 0.6409\n",
      "Episode: 191, Episode reward: 17.0, Elapsed time: 7.723932194709778 minutes, Epsilon 0.639\n",
      "Episode: 192, Episode reward: 89.0, Elapsed time: 7.85947787364324 minutes, Epsilon 0.6371\n",
      "Episode: 193, Episode reward: 71.0, Elapsed time: 7.989521817366282 minutes, Epsilon 0.6352\n",
      "Episode: 194, Episode reward: 65.0, Elapsed time: 8.119322339693705 minutes, Epsilon 0.6333\n",
      "Episode: 195, Episode reward: 81.0, Elapsed time: 8.26579355398814 minutes, Epsilon 0.6314\n",
      "Episode: 196, Episode reward: 51.0, Elapsed time: 8.327057484785716 minutes, Epsilon 0.6295\n",
      "Episode: 197, Episode reward: 59.0, Elapsed time: 8.39714929262797 minutes, Epsilon 0.6275999999999999\n",
      "Episode: 198, Episode reward: 30.0, Elapsed time: 8.432453886667888 minutes, Epsilon 0.6256999999999999\n",
      "Episode: 199, Episode reward: 18.0, Elapsed time: 8.453298517068227 minutes, Epsilon 0.6238\n",
      "Episode: 200, Episode reward: 79.0, Elapsed time: 8.549708954493205 minutes, Epsilon 0.6219\n",
      "Episode: 201, Episode reward: 111.0, Elapsed time: 8.67855855623881 minutes, Epsilon 0.62\n",
      "Episode: 202, Episode reward: 106.0, Elapsed time: 8.800428378582001 minutes, Epsilon 0.6181\n",
      "Episode: 203, Episode reward: 97.0, Elapsed time: 8.913502168655395 minutes, Epsilon 0.6162000000000001\n",
      "Episode: 204, Episode reward: 40.0, Elapsed time: 8.959649868806203 minutes, Epsilon 0.6143000000000001\n",
      "Episode: 205, Episode reward: 14.0, Elapsed time: 8.976258170604705 minutes, Epsilon 0.6124\n",
      "Episode: 206, Episode reward: 38.0, Elapsed time: 9.020437113444011 minutes, Epsilon 0.6105\n",
      "Episode: 207, Episode reward: 24.0, Elapsed time: 9.047487088044484 minutes, Epsilon 0.6086\n",
      "Episode: 208, Episode reward: 77.0, Elapsed time: 9.137458097934722 minutes, Epsilon 0.6067\n",
      "Episode: 209, Episode reward: 39.0, Elapsed time: 9.182188538710276 minutes, Epsilon 0.6048\n",
      "Episode: 210, Episode reward: 18.0, Elapsed time: 9.203555142879486 minutes, Epsilon 0.6029\n",
      "Episode: 211, Episode reward: 76.0, Elapsed time: 9.29265590508779 minutes, Epsilon 0.601\n",
      "Episode: 212, Episode reward: 67.0, Elapsed time: 9.369596540927887 minutes, Epsilon 0.5991\n",
      "Episode: 213, Episode reward: 27.0, Elapsed time: 9.401949934164683 minutes, Epsilon 0.5972\n",
      "Episode: 214, Episode reward: 70.0, Elapsed time: 9.484289745489756 minutes, Epsilon 0.5952999999999999\n",
      "Episode: 215, Episode reward: 84.0, Elapsed time: 9.583549479643503 minutes, Epsilon 0.5933999999999999\n",
      "Episode: 216, Episode reward: 153.0, Elapsed time: 9.759395031134288 minutes, Epsilon 0.5915\n",
      "Episode: 217, Episode reward: 31.0, Elapsed time: 9.795419283707936 minutes, Epsilon 0.5896\n",
      "Episode: 218, Episode reward: 11.0, Elapsed time: 9.808314649264018 minutes, Epsilon 0.5877\n",
      "Episode: 219, Episode reward: 13.0, Elapsed time: 9.823644411563873 minutes, Epsilon 0.5858\n",
      "Episode: 220, Episode reward: 106.0, Elapsed time: 9.948963868618012 minutes, Epsilon 0.5839\n",
      "Episode: 221, Episode reward: 12.0, Elapsed time: 9.963328993320465 minutes, Epsilon 0.5820000000000001\n",
      "Episode: 222, Episode reward: 137.0, Elapsed time: 10.124682068824768 minutes, Epsilon 0.5801000000000001\n",
      "Episode: 223, Episode reward: 96.0, Elapsed time: 10.235315632820129 minutes, Epsilon 0.5782\n",
      "Episode: 224, Episode reward: 151.0, Elapsed time: 10.414283533891043 minutes, Epsilon 0.5763\n",
      "Episode: 225, Episode reward: 45.0, Elapsed time: 10.467571051915487 minutes, Epsilon 0.5744\n",
      "Episode: 226, Episode reward: 85.0, Elapsed time: 10.566310636202495 minutes, Epsilon 0.5725\n",
      "Episode: 227, Episode reward: 176.0, Elapsed time: 10.769867952664693 minutes, Epsilon 0.5706\n",
      "Episode: 228, Episode reward: 126.0, Elapsed time: 10.920304719607035 minutes, Epsilon 0.5687\n",
      "Episode: 229, Episode reward: 71.0, Elapsed time: 11.002542050679525 minutes, Epsilon 0.5668\n",
      "Episode: 230, Episode reward: 73.0, Elapsed time: 11.087495958805084 minutes, Epsilon 0.5649\n",
      "Episode: 231, Episode reward: 50.0, Elapsed time: 11.14504630168279 minutes, Epsilon 0.563\n",
      "Episode: 232, Episode reward: 75.0, Elapsed time: 11.232736241817474 minutes, Epsilon 0.5610999999999999\n",
      "Episode: 233, Episode reward: 78.0, Elapsed time: 11.325027517477672 minutes, Epsilon 0.5591999999999999\n",
      "Episode: 234, Episode reward: 159.0, Elapsed time: 11.511758069197336 minutes, Epsilon 0.5573\n",
      "Episode: 235, Episode reward: 155.0, Elapsed time: 11.691025424003602 minutes, Epsilon 0.5554\n",
      "Episode: 236, Episode reward: 186.0, Elapsed time: 11.909495985507965 minutes, Epsilon 0.5535\n",
      "Episode: 237, Episode reward: 167.0, Elapsed time: 12.10379244486491 minutes, Epsilon 0.5516\n",
      "Episode: 238, Episode reward: 157.0, Elapsed time: 12.287071740627288 minutes, Epsilon 0.5497000000000001\n",
      "Episode: 239, Episode reward: 174.0, Elapsed time: 12.489643275737762 minutes, Epsilon 0.5478000000000001\n",
      "Episode: 240, Episode reward: 140.0, Elapsed time: 12.652833394209544 minutes, Epsilon 0.5459\n",
      "Episode: 241, Episode reward: 95.0, Elapsed time: 12.761748945713043 minutes, Epsilon 0.544\n",
      "Episode: 242, Episode reward: 98.0, Elapsed time: 12.876528942584992 minutes, Epsilon 0.5421\n",
      "Episode: 243, Episode reward: 219.0, Elapsed time: 13.129373562335967 minutes, Epsilon 0.5402\n",
      "Episode: 244, Episode reward: 137.0, Elapsed time: 13.290681374073028 minutes, Epsilon 0.5383\n",
      "Episode: 245, Episode reward: 174.0, Elapsed time: 13.49462726910909 minutes, Epsilon 0.5364\n",
      "Episode: 246, Episode reward: 184.0, Elapsed time: 13.707758327325186 minutes, Epsilon 0.5345\n",
      "Episode: 247, Episode reward: 25.0, Elapsed time: 13.736658088366191 minutes, Epsilon 0.5326\n",
      "Episode: 248, Episode reward: 116.0, Elapsed time: 13.871876970926921 minutes, Epsilon 0.5307\n",
      "Episode: 249, Episode reward: 25.0, Elapsed time: 13.901665023962657 minutes, Epsilon 0.5287999999999999\n",
      "Episode: 250, Episode reward: 152.0, Elapsed time: 14.080893127123515 minutes, Epsilon 0.5268999999999999\n",
      "Episode: 251, Episode reward: 201.0, Elapsed time: 14.313901766141255 minutes, Epsilon 0.525\n",
      "Episode: 252, Episode reward: 60.0, Elapsed time: 14.383684543768565 minutes, Epsilon 0.5231\n",
      "Episode: 253, Episode reward: 55.0, Elapsed time: 14.447641722361247 minutes, Epsilon 0.5212\n",
      "Episode: 254, Episode reward: 59.0, Elapsed time: 14.516477040449779 minutes, Epsilon 0.5193\n",
      "Episode: 255, Episode reward: 99.0, Elapsed time: 14.631411838531495 minutes, Epsilon 0.5174000000000001\n",
      "Episode: 256, Episode reward: 43.0, Elapsed time: 14.68195641040802 minutes, Epsilon 0.5155000000000001\n",
      "Episode: 257, Episode reward: 159.0, Elapsed time: 14.86692331234614 minutes, Epsilon 0.5136000000000001\n",
      "Episode: 258, Episode reward: 89.0, Elapsed time: 14.97121700445811 minutes, Epsilon 0.5117\n",
      "Episode: 259, Episode reward: 69.0, Elapsed time: 15.05395101706187 minutes, Epsilon 0.5098\n",
      "Episode: 260, Episode reward: 85.0, Elapsed time: 15.152669135729472 minutes, Epsilon 0.5079\n",
      "Episode: 261, Episode reward: 237.0, Elapsed time: 15.494154957930247 minutes, Epsilon 0.506\n",
      "Episode: 262, Episode reward: 285.0, Elapsed time: 15.887755942344665 minutes, Epsilon 0.5041\n",
      "Episode: 263, Episode reward: 25.0, Elapsed time: 15.925677613417308 minutes, Epsilon 0.5022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 264, Episode reward: 103.0, Elapsed time: 16.067035885651908 minutes, Epsilon 0.5003\n",
      "Episode: 265, Episode reward: 199.0, Elapsed time: 16.334607048829398 minutes, Epsilon 0.49839999999999995\n",
      "Episode: 266, Episode reward: 197.0, Elapsed time: 16.597690172990163 minutes, Epsilon 0.49650000000000005\n",
      "Episode: 267, Episode reward: 246.0, Elapsed time: 16.927860856056213 minutes, Epsilon 0.49460000000000004\n",
      "Episode: 268, Episode reward: 415.0, Elapsed time: 17.48865399360657 minutes, Epsilon 0.4927\n",
      "Episode: 269, Episode reward: 263.0, Elapsed time: 17.843604203065237 minutes, Epsilon 0.4908\n",
      "Episode: 270, Episode reward: 329.0, Elapsed time: 18.283432006835938 minutes, Epsilon 0.4889\n",
      "Episode: 271, Episode reward: 125.0, Elapsed time: 18.450606230894724 minutes, Epsilon 0.487\n",
      "Episode: 272, Episode reward: 415.0, Elapsed time: 19.034395519892374 minutes, Epsilon 0.4851\n",
      "Episode: 273, Episode reward: 102.0, Elapsed time: 19.218740753332774 minutes, Epsilon 0.48319999999999996\n",
      "Episode: 274, Episode reward: 154.0, Elapsed time: 19.47245053847631 minutes, Epsilon 0.48129999999999995\n",
      "Episode: 275, Episode reward: 14.0, Elapsed time: 19.49287097056707 minutes, Epsilon 0.47940000000000005\n",
      "Episode: 276, Episode reward: 117.0, Elapsed time: 19.685090045134228 minutes, Epsilon 0.47750000000000004\n",
      "Episode: 277, Episode reward: 246.0, Elapsed time: 19.982983557383218 minutes, Epsilon 0.4756\n",
      "Episode: 278, Episode reward: 181.0, Elapsed time: 20.19963347117106 minutes, Epsilon 0.4737\n",
      "Episode: 279, Episode reward: 161.0, Elapsed time: 20.432730555534363 minutes, Epsilon 0.4718\n",
      "Episode: 280, Episode reward: 145.0, Elapsed time: 20.63275917371114 minutes, Epsilon 0.4699\n",
      "Episode: 281, Episode reward: 313.0, Elapsed time: 21.010200317700704 minutes, Epsilon 0.46799999999999997\n",
      "Episode: 282, Episode reward: 66.0, Elapsed time: 21.07410720984141 minutes, Epsilon 0.46609999999999996\n",
      "Episode: 283, Episode reward: 212.0, Elapsed time: 21.282189770539603 minutes, Epsilon 0.46419999999999995\n",
      "Episode: 284, Episode reward: 172.0, Elapsed time: 21.450885077317555 minutes, Epsilon 0.46230000000000004\n",
      "Episode: 285, Episode reward: 190.0, Elapsed time: 21.637658111254375 minutes, Epsilon 0.46040000000000003\n",
      "Episode: 286, Episode reward: 71.0, Elapsed time: 21.70764132340749 minutes, Epsilon 0.4585\n",
      "Episode: 287, Episode reward: 225.0, Elapsed time: 21.93522605498632 minutes, Epsilon 0.4566\n",
      "Episode: 288, Episode reward: 106.0, Elapsed time: 22.040146386623384 minutes, Epsilon 0.4547\n",
      "Episode: 289, Episode reward: 117.0, Elapsed time: 22.155205698808036 minutes, Epsilon 0.4528\n",
      "Episode: 290, Episode reward: 251.0, Elapsed time: 22.403953643639884 minutes, Epsilon 0.45089999999999997\n",
      "Episode: 291, Episode reward: 234.0, Elapsed time: 22.636072397232056 minutes, Epsilon 0.44899999999999995\n",
      "Episode: 292, Episode reward: 13.0, Elapsed time: 22.649210365613303 minutes, Epsilon 0.44710000000000005\n",
      "Episode: 293, Episode reward: 217.0, Elapsed time: 22.863928457101185 minutes, Epsilon 0.44520000000000004\n",
      "Episode: 294, Episode reward: 259.0, Elapsed time: 23.120734202861787 minutes, Epsilon 0.4433\n",
      "Episode: 295, Episode reward: 35.0, Elapsed time: 23.155188981691996 minutes, Epsilon 0.4414\n",
      "Episode: 296, Episode reward: 117.0, Elapsed time: 23.27103134791056 minutes, Epsilon 0.4395\n",
      "Episode: 297, Episode reward: 235.0, Elapsed time: 23.508340966701507 minutes, Epsilon 0.4376\n",
      "Episode: 298, Episode reward: 448.0, Elapsed time: 23.96102770169576 minutes, Epsilon 0.4357\n",
      "Episode: 299, Episode reward: 178.0, Elapsed time: 24.13676485220591 minutes, Epsilon 0.43379999999999996\n",
      "Episode: 300, Episode reward: 311.0, Elapsed time: 24.464854180812836 minutes, Epsilon 0.43189999999999995\n",
      "Episode: 301, Episode reward: 201.0, Elapsed time: 24.66423424084981 minutes, Epsilon 0.43000000000000005\n",
      "Episode: 302, Episode reward: 318.0, Elapsed time: 24.981146093209585 minutes, Epsilon 0.42810000000000004\n",
      "Episode: 303, Episode reward: 111.0, Elapsed time: 25.090546321868896 minutes, Epsilon 0.4262\n",
      "Episode: 304, Episode reward: 475.0, Elapsed time: 25.56345670223236 minutes, Epsilon 0.4243\n",
      "Episode: 305, Episode reward: 47.0, Elapsed time: 25.610234014193217 minutes, Epsilon 0.4224\n",
      "Episode: 306, Episode reward: 229.0, Elapsed time: 25.835316904385884 minutes, Epsilon 0.4205\n",
      "Episode: 307, Episode reward: 120.0, Elapsed time: 25.95596526861191 minutes, Epsilon 0.41859999999999997\n",
      "Episode: 308, Episode reward: 338.0, Elapsed time: 26.289273591836295 minutes, Epsilon 0.41669999999999996\n",
      "Episode: 309, Episode reward: 203.0, Elapsed time: 26.48955318927765 minutes, Epsilon 0.41479999999999995\n",
      "Episode: 310, Episode reward: 242.0, Elapsed time: 26.728740266958873 minutes, Epsilon 0.41290000000000004\n",
      "Episode: 311, Episode reward: 427.0, Elapsed time: 27.15421436627706 minutes, Epsilon 0.41100000000000003\n",
      "Episode: 312, Episode reward: 215.0, Elapsed time: 27.37562200228373 minutes, Epsilon 0.4091\n",
      "Episode: 313, Episode reward: 31.0, Elapsed time: 27.406417727470398 minutes, Epsilon 0.4072\n",
      "Episode: 314, Episode reward: 244.0, Elapsed time: 27.64603298107783 minutes, Epsilon 0.4053\n",
      "Episode: 315, Episode reward: 244.0, Elapsed time: 27.88867290019989 minutes, Epsilon 0.4034\n",
      "Episode: 316, Episode reward: 217.0, Elapsed time: 28.102952098846437 minutes, Epsilon 0.40149999999999997\n",
      "Episode: 317, Episode reward: 306.0, Elapsed time: 28.407346510887145 minutes, Epsilon 0.39959999999999996\n",
      "Episode: 318, Episode reward: 65.0, Elapsed time: 28.472851634025574 minutes, Epsilon 0.39770000000000005\n",
      "Episode: 319, Episode reward: 46.0, Elapsed time: 28.518493739763894 minutes, Epsilon 0.39580000000000004\n",
      "Episode: 320, Episode reward: 235.0, Elapsed time: 28.752709917227428 minutes, Epsilon 0.39390000000000003\n",
      "Episode: 321, Episode reward: 270.0, Elapsed time: 29.02549520333608 minutes, Epsilon 0.392\n",
      "Episode: 322, Episode reward: 268.0, Elapsed time: 29.289973815282185 minutes, Epsilon 0.3901\n",
      "Episode: 323, Episode reward: 436.0, Elapsed time: 29.722657187779745 minutes, Epsilon 0.3882\n",
      "Episode: 324, Episode reward: 290.0, Elapsed time: 30.009554107983906 minutes, Epsilon 0.3863\n",
      "Episode: 325, Episode reward: 287.0, Elapsed time: 30.293986443678538 minutes, Epsilon 0.38439999999999996\n",
      "Episode: 326, Episode reward: 198.0, Elapsed time: 30.491361506779988 minutes, Epsilon 0.38249999999999995\n",
      "Episode: 327, Episode reward: 182.0, Elapsed time: 30.671746436754862 minutes, Epsilon 0.38060000000000005\n",
      "Episode: 328, Episode reward: 229.0, Elapsed time: 30.90122014284134 minutes, Epsilon 0.37870000000000004\n",
      "Episode: 329, Episode reward: 264.0, Elapsed time: 31.16646142800649 minutes, Epsilon 0.3768\n",
      "Episode: 330, Episode reward: 205.0, Elapsed time: 31.369930561383566 minutes, Epsilon 0.3749\n",
      "Episode: 331, Episode reward: 315.0, Elapsed time: 31.68418467839559 minutes, Epsilon 0.373\n",
      "Episode: 332, Episode reward: 475.0, Elapsed time: 32.155574019749956 minutes, Epsilon 0.3711\n",
      "Episode: 333, Episode reward: 475.0, Elapsed time: 32.62942619323731 minutes, Epsilon 0.3692\n",
      "Episode: 334, Episode reward: 321.0, Elapsed time: 32.948360459009805 minutes, Epsilon 0.36729999999999996\n",
      "Episode: 335, Episode reward: 282.0, Elapsed time: 33.22690619230271 minutes, Epsilon 0.36539999999999995\n",
      "Episode: 336, Episode reward: 168.0, Elapsed time: 33.394193204243976 minutes, Epsilon 0.36350000000000005\n",
      "Episode: 337, Episode reward: 376.0, Elapsed time: 33.76877163648605 minutes, Epsilon 0.36160000000000003\n",
      "Episode: 338, Episode reward: 475.0, Elapsed time: 34.243374943733215 minutes, Epsilon 0.3597\n",
      "Episode: 339, Episode reward: 444.0, Elapsed time: 34.68419580856959 minutes, Epsilon 0.3578\n",
      "Episode: 340, Episode reward: 475.0, Elapsed time: 35.154680740833285 minutes, Epsilon 0.3559\n",
      "Episode: 341, Episode reward: 346.0, Elapsed time: 35.498808864752455 minutes, Epsilon 0.354\n",
      "Episode: 342, Episode reward: 317.0, Elapsed time: 35.81277056535085 minutes, Epsilon 0.35209999999999997\n",
      "Episode: 343, Episode reward: 300.0, Elapsed time: 36.11290938854218 minutes, Epsilon 0.35019999999999996\n",
      "Episode: 344, Episode reward: 298.0, Elapsed time: 36.40866016546885 minutes, Epsilon 0.34830000000000005\n",
      "Episode: 345, Episode reward: 475.0, Elapsed time: 36.87964007854462 minutes, Epsilon 0.34640000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 346, Episode reward: 281.0, Elapsed time: 37.15765565633774 minutes, Epsilon 0.34450000000000003\n",
      "Episode: 347, Episode reward: 475.0, Elapsed time: 37.62981239159902 minutes, Epsilon 0.3426\n",
      "Episode: 348, Episode reward: 475.0, Elapsed time: 38.10224097172419 minutes, Epsilon 0.3407\n",
      "Episode: 349, Episode reward: 293.0, Elapsed time: 38.394745361804965 minutes, Epsilon 0.3388\n",
      "Episode: 350, Episode reward: 294.0, Elapsed time: 38.687944261233014 minutes, Epsilon 0.3369\n",
      "Episode: 351, Episode reward: 298.0, Elapsed time: 38.983802390098575 minutes, Epsilon 0.33499999999999996\n",
      "Episode: 352, Episode reward: 221.0, Elapsed time: 39.20240429242452 minutes, Epsilon 0.33309999999999995\n",
      "Episode: 353, Episode reward: 204.0, Elapsed time: 39.407935845851895 minutes, Epsilon 0.33120000000000005\n",
      "Episode: 354, Episode reward: 214.0, Elapsed time: 39.620498502254485 minutes, Epsilon 0.32930000000000004\n",
      "Episode: 355, Episode reward: 171.0, Elapsed time: 39.7899648865064 minutes, Epsilon 0.3274\n",
      "Episode: 356, Episode reward: 164.0, Elapsed time: 39.9539058526357 minutes, Epsilon 0.3255\n",
      "Episode: 357, Episode reward: 168.0, Elapsed time: 40.1203725417455 minutes, Epsilon 0.3236\n",
      "Episode: 358, Episode reward: 147.0, Elapsed time: 40.26704002221425 minutes, Epsilon 0.3217\n",
      "Episode: 359, Episode reward: 152.0, Elapsed time: 40.41849457025528 minutes, Epsilon 0.3198\n",
      "Episode: 360, Episode reward: 161.0, Elapsed time: 40.57913601795833 minutes, Epsilon 0.31789999999999996\n",
      "Episode: 361, Episode reward: 159.0, Elapsed time: 40.73618490298589 minutes, Epsilon 0.31599999999999995\n",
      "Episode: 362, Episode reward: 169.0, Elapsed time: 40.904959909121196 minutes, Epsilon 0.31410000000000005\n",
      "Episode: 363, Episode reward: 129.0, Elapsed time: 41.03237980604172 minutes, Epsilon 0.31220000000000003\n",
      "Episode: 364, Episode reward: 21.0, Elapsed time: 41.05317995150884 minutes, Epsilon 0.3103\n",
      "Episode: 365, Episode reward: 33.0, Elapsed time: 41.08572642803192 minutes, Epsilon 0.3084\n",
      "Episode: 366, Episode reward: 116.0, Elapsed time: 41.20009918610255 minutes, Epsilon 0.3065\n",
      "Episode: 367, Episode reward: 25.0, Elapsed time: 41.22460776567459 minutes, Epsilon 0.3046\n",
      "Episode: 368, Episode reward: 103.0, Elapsed time: 41.32647953430811 minutes, Epsilon 0.30269999999999997\n",
      "Episode: 369, Episode reward: 120.0, Elapsed time: 41.44582081635793 minutes, Epsilon 0.30079999999999996\n",
      "Episode: 370, Episode reward: 14.0, Elapsed time: 41.459925679365796 minutes, Epsilon 0.29890000000000005\n",
      "Episode: 371, Episode reward: 11.0, Elapsed time: 41.47103121678035 minutes, Epsilon 0.29700000000000004\n",
      "Episode: 372, Episode reward: 13.0, Elapsed time: 41.48418473800023 minutes, Epsilon 0.29510000000000003\n",
      "Episode: 373, Episode reward: 15.0, Elapsed time: 41.49906948407491 minutes, Epsilon 0.2932\n",
      "Episode: 374, Episode reward: 12.0, Elapsed time: 41.511270570755 minutes, Epsilon 0.2913\n",
      "Episode: 375, Episode reward: 12.0, Elapsed time: 41.52333365281423 minutes, Epsilon 0.2894\n",
      "Episode: 376, Episode reward: 19.0, Elapsed time: 41.542422707875566 minutes, Epsilon 0.2875\n",
      "Episode: 377, Episode reward: 115.0, Elapsed time: 41.65594981908798 minutes, Epsilon 0.28559999999999997\n",
      "Episode: 378, Episode reward: 28.0, Elapsed time: 41.68395165205002 minutes, Epsilon 0.28369999999999995\n",
      "Episode: 379, Episode reward: 9.0, Elapsed time: 41.69318666060766 minutes, Epsilon 0.28180000000000005\n",
      "Episode: 380, Episode reward: 22.0, Elapsed time: 41.71506369908651 minutes, Epsilon 0.27990000000000004\n",
      "Episode: 381, Episode reward: 140.0, Elapsed time: 41.856884984175366 minutes, Epsilon 0.278\n",
      "Episode: 382, Episode reward: 181.0, Elapsed time: 42.037104320526126 minutes, Epsilon 0.2761\n",
      "Episode: 383, Episode reward: 18.0, Elapsed time: 42.05517781178157 minutes, Epsilon 0.2742\n",
      "Episode: 384, Episode reward: 472.0, Elapsed time: 42.52562692562739 minutes, Epsilon 0.2723\n",
      "Episode: 385, Episode reward: 475.0, Elapsed time: 42.99529948234558 minutes, Epsilon 0.2704\n",
      "Episode: 386, Episode reward: 475.0, Elapsed time: 43.46674679120382 minutes, Epsilon 0.26849999999999996\n",
      "Episode: 387, Episode reward: 44.0, Elapsed time: 43.5108602364858 minutes, Epsilon 0.26659999999999995\n",
      "Episode: 388, Episode reward: 475.0, Elapsed time: 43.98285059928894 minutes, Epsilon 0.26470000000000005\n",
      "Episode: 389, Episode reward: 475.0, Elapsed time: 44.45343432426453 minutes, Epsilon 0.26280000000000003\n",
      "Episode: 390, Episode reward: 475.0, Elapsed time: 44.92474267482758 minutes, Epsilon 0.2609\n",
      "Episode: 391, Episode reward: 475.0, Elapsed time: 45.395548057556155 minutes, Epsilon 0.259\n",
      "Episode: 392, Episode reward: 475.0, Elapsed time: 45.86686030626297 minutes, Epsilon 0.2571\n",
      "Episode: 393, Episode reward: 475.0, Elapsed time: 46.33610801696777 minutes, Epsilon 0.2552\n",
      "Episode: 394, Episode reward: 475.0, Elapsed time: 46.804662175973256 minutes, Epsilon 0.25329999999999997\n",
      "Episode: 395, Episode reward: 475.0, Elapsed time: 47.275816929340365 minutes, Epsilon 0.25139999999999996\n",
      "Episode: 396, Episode reward: 475.0, Elapsed time: 47.74620869557063 minutes, Epsilon 0.24950000000000006\n",
      "Episode: 397, Episode reward: 475.0, Elapsed time: 48.21848667462667 minutes, Epsilon 0.24760000000000004\n",
      "Episode: 398, Episode reward: 475.0, Elapsed time: 48.68895134131114 minutes, Epsilon 0.24570000000000003\n",
      "Episode: 399, Episode reward: 475.0, Elapsed time: 49.15878237088521 minutes, Epsilon 0.24380000000000002\n",
      "Episode: 400, Episode reward: 475.0, Elapsed time: 49.629366874694824 minutes, Epsilon 0.2419\n",
      "Episode: 401, Episode reward: 475.0, Elapsed time: 50.099972466627754 minutes, Epsilon 0.24\n",
      "Episode: 402, Episode reward: 475.0, Elapsed time: 50.571551370620725 minutes, Epsilon 0.23809999999999998\n",
      "Episode: 403, Episode reward: 475.0, Elapsed time: 51.04137782255808 minutes, Epsilon 0.23619999999999997\n",
      "Episode: 404, Episode reward: 475.0, Elapsed time: 51.511126311620075 minutes, Epsilon 0.23429999999999995\n",
      "Episode: 405, Episode reward: 475.0, Elapsed time: 51.986124436060585 minutes, Epsilon 0.23240000000000005\n",
      "Episode: 406, Episode reward: 475.0, Elapsed time: 52.456461179256436 minutes, Epsilon 0.23050000000000004\n",
      "Episode: 407, Episode reward: 475.0, Elapsed time: 52.925538841883345 minutes, Epsilon 0.22860000000000003\n",
      "Episode: 408, Episode reward: 475.0, Elapsed time: 53.396555368105574 minutes, Epsilon 0.2267\n",
      "Episode: 409, Episode reward: 475.0, Elapsed time: 53.86793953577678 minutes, Epsilon 0.2248\n",
      "Episode: 410, Episode reward: 294.0, Elapsed time: 54.16163203716278 minutes, Epsilon 0.2229\n",
      "Episode: 411, Episode reward: 12.0, Elapsed time: 54.17373003562292 minutes, Epsilon 0.22099999999999997\n",
      "Episode: 412, Episode reward: 13.0, Elapsed time: 54.18687889178594 minutes, Epsilon 0.21909999999999996\n",
      "Episode: 413, Episode reward: 21.0, Elapsed time: 54.20777243375778 minutes, Epsilon 0.21719999999999995\n",
      "Episode: 414, Episode reward: 116.0, Elapsed time: 54.32974464098613 minutes, Epsilon 0.21530000000000005\n",
      "Episode: 415, Episode reward: 13.0, Elapsed time: 54.34339759349823 minutes, Epsilon 0.21340000000000003\n",
      "Episode: 416, Episode reward: 154.0, Elapsed time: 54.49903555313746 minutes, Epsilon 0.21150000000000002\n",
      "Episode: 417, Episode reward: 167.0, Elapsed time: 54.66418483654658 minutes, Epsilon 0.2096\n",
      "Episode: 418, Episode reward: 14.0, Elapsed time: 54.67835596005122 minutes, Epsilon 0.2077\n",
      "Episode: 419, Episode reward: 10.0, Elapsed time: 54.68850840727488 minutes, Epsilon 0.20579999999999998\n",
      "Episode: 420, Episode reward: 170.0, Elapsed time: 54.85564514001211 minutes, Epsilon 0.20389999999999997\n",
      "Episode: 421, Episode reward: 216.0, Elapsed time: 55.068971240520476 minutes, Epsilon 0.20199999999999996\n",
      "Episode: 422, Episode reward: 475.0, Elapsed time: 55.54074873129527 minutes, Epsilon 0.20010000000000006\n",
      "Episode: 423, Episode reward: 373.0, Elapsed time: 55.91046938101451 minutes, Epsilon 0.19820000000000004\n",
      "Episode: 424, Episode reward: 475.0, Elapsed time: 56.38085448741913 minutes, Epsilon 0.19630000000000003\n",
      "Episode: 425, Episode reward: 475.0, Elapsed time: 56.84943659702937 minutes, Epsilon 0.19440000000000002\n",
      "Episode: 426, Episode reward: 475.0, Elapsed time: 57.32077467441559 minutes, Epsilon 0.1925\n",
      "Episode: 427, Episode reward: 475.0, Elapsed time: 57.79095301230748 minutes, Epsilon 0.1906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 428, Episode reward: 475.0, Elapsed time: 58.26215262413025 minutes, Epsilon 0.18869999999999998\n",
      "Episode: 429, Episode reward: 475.0, Elapsed time: 58.73353768587113 minutes, Epsilon 0.18679999999999997\n",
      "Episode: 430, Episode reward: 475.0, Elapsed time: 59.39677335818609 minutes, Epsilon 0.18489999999999995\n",
      "Episode: 431, Episode reward: 475.0, Elapsed time: 60.05851257244746 minutes, Epsilon 0.18300000000000005\n",
      "Episode: 432, Episode reward: 475.0, Elapsed time: 60.79817719856898 minutes, Epsilon 0.18110000000000004\n",
      "Episode: 433, Episode reward: 475.0, Elapsed time: 61.46475914319356 minutes, Epsilon 0.17920000000000003\n",
      "Episode: 434, Episode reward: 475.0, Elapsed time: 62.14958671331406 minutes, Epsilon 0.1773\n",
      "Episode: 435, Episode reward: 475.0, Elapsed time: 62.81350075006485 minutes, Epsilon 0.1754\n",
      "Episode: 436, Episode reward: 475.0, Elapsed time: 63.47507603168488 minutes, Epsilon 0.1735\n",
      "Episode: 437, Episode reward: 475.0, Elapsed time: 64.13497395515442 minutes, Epsilon 0.17159999999999997\n",
      "Episode: 438, Episode reward: 475.0, Elapsed time: 64.79587239027023 minutes, Epsilon 0.16969999999999996\n",
      "Episode: 439, Episode reward: 475.0, Elapsed time: 65.45952035188675 minutes, Epsilon 0.16779999999999995\n",
      "Episode: 440, Episode reward: 475.0, Elapsed time: 66.12553985913594 minutes, Epsilon 0.16590000000000005\n",
      "Episode: 441, Episode reward: 475.0, Elapsed time: 66.63030652602514 minutes, Epsilon 0.16400000000000003\n",
      "Episode: 442, Episode reward: 221.0, Elapsed time: 66.84807201226552 minutes, Epsilon 0.16210000000000002\n",
      "Episode: 443, Episode reward: 16.0, Elapsed time: 66.86705208222071 minutes, Epsilon 0.1602\n",
      "Episode: 444, Episode reward: 125.0, Elapsed time: 66.99051863352457 minutes, Epsilon 0.1583\n",
      "Episode: 445, Episode reward: 116.0, Elapsed time: 67.10526283979416 minutes, Epsilon 0.15639999999999998\n",
      "Episode: 446, Episode reward: 103.0, Elapsed time: 67.20725071032842 minutes, Epsilon 0.15449999999999997\n",
      "Episode: 447, Episode reward: 102.0, Elapsed time: 67.30861623287201 minutes, Epsilon 0.15259999999999996\n",
      "Episode: 448, Episode reward: 97.0, Elapsed time: 67.40393588940303 minutes, Epsilon 0.15070000000000006\n",
      "Episode: 449, Episode reward: 107.0, Elapsed time: 67.5106385231018 minutes, Epsilon 0.14880000000000004\n",
      "Episode: 450, Episode reward: 106.0, Elapsed time: 67.61532949209213 minutes, Epsilon 0.14690000000000003\n",
      "Episode: 451, Episode reward: 101.0, Elapsed time: 67.71526922782262 minutes, Epsilon 0.14500000000000002\n",
      "Episode: 452, Episode reward: 109.0, Elapsed time: 67.8256861726443 minutes, Epsilon 0.1431\n",
      "Episode: 453, Episode reward: 107.0, Elapsed time: 67.9361174941063 minutes, Epsilon 0.1412\n",
      "Episode: 454, Episode reward: 108.0, Elapsed time: 68.04319676955541 minutes, Epsilon 0.13929999999999998\n",
      "Episode: 455, Episode reward: 103.0, Elapsed time: 68.14538673559825 minutes, Epsilon 0.13739999999999997\n",
      "Episode: 456, Episode reward: 116.0, Elapsed time: 68.26004579067231 minutes, Epsilon 0.13549999999999995\n",
      "Episode: 457, Episode reward: 19.0, Elapsed time: 68.27890452543895 minutes, Epsilon 0.13360000000000005\n",
      "Episode: 458, Episode reward: 124.0, Elapsed time: 68.40242824951808 minutes, Epsilon 0.13170000000000004\n",
      "Episode: 459, Episode reward: 134.0, Elapsed time: 68.53538693189621 minutes, Epsilon 0.12980000000000003\n",
      "Episode: 460, Episode reward: 475.0, Elapsed time: 69.00749897956848 minutes, Epsilon 0.1279\n",
      "Episode: 461, Episode reward: 475.0, Elapsed time: 69.52790016730627 minutes, Epsilon 0.126\n",
      "Episode: 462, Episode reward: 475.0, Elapsed time: 70.00243666172028 minutes, Epsilon 0.12409999999999999\n",
      "Episode: 463, Episode reward: 475.0, Elapsed time: 70.47450235287349 minutes, Epsilon 0.12219999999999998\n",
      "Episode: 464, Episode reward: 475.0, Elapsed time: 70.96260749101639 minutes, Epsilon 0.12029999999999996\n",
      "Episode: 465, Episode reward: 387.0, Elapsed time: 71.53558454910915 minutes, Epsilon 0.11839999999999995\n",
      "Episode: 466, Episode reward: 211.0, Elapsed time: 71.8322641213735 minutes, Epsilon 0.11650000000000005\n",
      "Episode: 467, Episode reward: 194.0, Elapsed time: 72.10879834493001 minutes, Epsilon 0.11460000000000004\n",
      "Episode: 468, Episode reward: 164.0, Elapsed time: 72.33716489076615 minutes, Epsilon 0.11270000000000002\n",
      "Episode: 469, Episode reward: 196.0, Elapsed time: 72.61168941656749 minutes, Epsilon 0.11080000000000001\n",
      "Episode: 470, Episode reward: 164.0, Elapsed time: 72.803009780248 minutes, Epsilon 0.1089\n",
      "Episode: 471, Episode reward: 166.0, Elapsed time: 72.99702468713124 minutes, Epsilon 0.10699999999999998\n",
      "Episode: 472, Episode reward: 165.0, Elapsed time: 73.19006985823313 minutes, Epsilon 0.10509999999999997\n",
      "Episode: 473, Episode reward: 200.0, Elapsed time: 73.42954593896866 minutes, Epsilon 0.10319999999999996\n",
      "Episode: 474, Episode reward: 202.0, Elapsed time: 73.70465539296468 minutes, Epsilon 0.10130000000000006\n",
      "Episode: 475, Episode reward: 200.0, Elapsed time: 73.94370408058167 minutes, Epsilon 0.09940000000000004\n",
      "Episode: 476, Episode reward: 174.0, Elapsed time: 74.1691548148791 minutes, Epsilon 0.09750000000000003\n",
      "Episode: 477, Episode reward: 189.0, Elapsed time: 74.44180296262105 minutes, Epsilon 0.09560000000000002\n",
      "Episode: 478, Episode reward: 262.0, Elapsed time: 74.81407922506332 minutes, Epsilon 0.0937\n",
      "Episode: 479, Episode reward: 475.0, Elapsed time: 75.51118750174841 minutes, Epsilon 0.09179999999999999\n",
      "Episode: 480, Episode reward: 404.0, Elapsed time: 76.09778535763422 minutes, Epsilon 0.08989999999999998\n",
      "Episode: 481, Episode reward: 475.0, Elapsed time: 76.75763735771179 minutes, Epsilon 0.08799999999999997\n",
      "Episode: 482, Episode reward: 475.0, Elapsed time: 77.42355740070343 minutes, Epsilon 0.08609999999999995\n",
      "Episode: 483, Episode reward: 475.0, Elapsed time: 78.08060862620671 minutes, Epsilon 0.08420000000000005\n",
      "Episode: 484, Episode reward: 475.0, Elapsed time: 78.74284257491429 minutes, Epsilon 0.08230000000000004\n",
      "Episode: 485, Episode reward: 475.0, Elapsed time: 79.40490366617838 minutes, Epsilon 0.08040000000000003\n",
      "Episode: 486, Episode reward: 475.0, Elapsed time: 80.07181249856949 minutes, Epsilon 0.07850000000000001\n",
      "Episode: 487, Episode reward: 475.0, Elapsed time: 80.72667320569356 minutes, Epsilon 0.0766\n",
      "Episode: 488, Episode reward: 19.0, Elapsed time: 80.75560608704885 minutes, Epsilon 0.07469999999999999\n",
      "Episode: 489, Episode reward: 21.0, Elapsed time: 80.78953392108282 minutes, Epsilon 0.07279999999999998\n",
      "Episode: 490, Episode reward: 23.0, Elapsed time: 80.82532567580542 minutes, Epsilon 0.07089999999999996\n",
      "Episode: 491, Episode reward: 24.0, Elapsed time: 80.86342811187109 minutes, Epsilon 0.06899999999999995\n",
      "Episode: 492, Episode reward: 29.0, Elapsed time: 80.90547252893448 minutes, Epsilon 0.06710000000000005\n",
      "Episode: 493, Episode reward: 20.0, Elapsed time: 80.93588428894678 minutes, Epsilon 0.06520000000000004\n",
      "Episode: 494, Episode reward: 22.0, Elapsed time: 80.96744603713354 minutes, Epsilon 0.06330000000000002\n",
      "Episode: 495, Episode reward: 20.0, Elapsed time: 80.99619801044464 minutes, Epsilon 0.06140000000000001\n",
      "Episode: 496, Episode reward: 19.0, Elapsed time: 81.02284262180328 minutes, Epsilon 0.0595\n",
      "Episode: 497, Episode reward: 21.0, Elapsed time: 81.05307232141494 minutes, Epsilon 0.057599999999999985\n",
      "Episode: 498, Episode reward: 23.0, Elapsed time: 81.0859649380048 minutes, Epsilon 0.05569999999999997\n",
      "Episode: 499, Episode reward: 25.0, Elapsed time: 81.12118537425995 minutes, Epsilon 0.05379999999999996\n"
     ]
    }
   ],
   "source": [
    " #results, also plot average, and avarge over episodes\n",
    " #for new environment; stack states, CNN\n",
    "\n",
    "#create and preprocess environment\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\", max_episode_steps = 475)\n",
    "env = FlattenObservation(env)\n",
    "state, info = env.reset()\n",
    "\n",
    "#settings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "max_run_time = 60*90\n",
    "n_episodes = 500\n",
    "algorithm = 'DDQN' #options: DQN and DDQN\n",
    "\n",
    "#initialize agent\n",
    "agent = Agent(algorithm = algorithm,\n",
    "              device = device,\n",
    "              n_actions = env.action_space.n,\n",
    "              state_size = state.size)\n",
    "\n",
    "#load agents online network with previously trained parameters and copy to target network\n",
    "#agent.NN_pred.load_state_dict(torch.load('model.pth'))\n",
    "#agent.NN_target = copy.deepcopy(agent.NN_pred)\n",
    "\n",
    "#for-loop: each loop initializes, simulates and logs one episode\n",
    "episodes_rewards = []\n",
    "average_rewards = []\n",
    "step_counter = 0\n",
    "start_time = time.time()\n",
    "for episode in range(1, n_episodes):\n",
    "\n",
    "    #initialize episode\n",
    "    episode_reward = 0\n",
    "    state, info = env.reset()\n",
    "    state = torch.from_numpy(state).to(device)\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    #while-loop: simulates one episodes, loops until agent reaches terminating state or environment is truncated\n",
    "    while not terminated and not truncated:\n",
    "\n",
    "        #select action\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        #perform one step and save experience\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        step_counter += 1\n",
    "        episode_reward += reward\n",
    "        next_state = torch.from_numpy(next_state).to(device)\n",
    "        agent.save_experience(state, action, reward, next_state, terminated, truncated)\n",
    "\n",
    "        #train online network\n",
    "        if step_counter > agent.batch_size:\n",
    "            agent.train()\n",
    "\n",
    "        #copy online network to target network\n",
    "        if step_counter % agent.copy_frequency == 0:\n",
    "            agent.copy()\n",
    "\n",
    "        #next state --> current state\n",
    "        state = next_state\n",
    "\n",
    "    #save episode reward\n",
    "    episodes_rewards.append(episode_reward)\n",
    "    average = sum(episodes_rewards)/len(episodes_rewards)\n",
    "    average_rewards.append(average)\n",
    "    \n",
    "    #calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f'Episode: {episode}, Episode reward: {episode_reward}, Elapsed time: {elapsed_time/60} minutes, Epsilon {agent.epsilon}')\n",
    "\n",
    "    #stop training if maximum running time is surpassed\n",
    "    if elapsed_time > max_run_time:\n",
    "        print(f'Breaking after {elapsed_time/60} minutes. Performed {len(episodes_rewards_list)} episodes, total steps: {step_counter}')\n",
    "        break\n",
    "\n",
    "    #decay epsilon\n",
    "    agent.calc_epsilon(episode, n_episodes)\n",
    "\n",
    "#save the online networks parameters\n",
    "torch.save(agent.NN_pred.state_dict(), 'model.pth')\n",
    "\n",
    "#close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024c5e4",
   "metadata": {
    "id": "5024c5e4"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8ea248",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "5a8ea248",
    "outputId": "fccd268c-584d-4589-8e4c-fd63df0261fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 499, Total frames: 71850\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Episodes: {len(episodes_rewards)}, Total frames: {step_counter}')\n",
    "\n",
    "#plot 1\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].set_title(f'{algorithm} Performance')\n",
    "ax[0].set_xlabel(\"Episode\")\n",
    "ax[0].set_ylabel(\"Reward\")\n",
    "x = range(len(episodes_rewards))\n",
    "y = episodes_rewards\n",
    "ax[0].plot(x, y, color =\"red\")\n",
    "\n",
    "#plot 2\n",
    "ax[1].set_title(f'{algorithm} Performance (average)')\n",
    "ax[1].set_xlabel(\"Episode\")\n",
    "ax[1].set_ylabel(\"Average Reward\")\n",
    "x = range(len(average_rewards))\n",
    "y = average_rewards\n",
    "ax[1].plot(x, y, color =\"red\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078206bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
